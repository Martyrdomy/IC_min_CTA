{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyTSL as pt\n",
    "import os\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from Config import factor_config as fc\n",
    "from Config import performance_config as pc\n",
    "\n",
    "head_future = pd.read_excel(os.path.join(fc.head_path, 'IC_head_future.xlsx')) # 每日主流合约"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def read_file(date):\n",
    "    '''\n",
    "    根据日期读取对应主头合约文件\n",
    "    '''\n",
    "    read_date = date.strftime('%Y%m%d')\n",
    "    next_idx = head_future[head_future['trade_date'] == date].index\n",
    "    if next_idx == 0:\n",
    "        return None\n",
    "    read_future = head_future.iloc[next_idx - 1]['IC'].values[0]\n",
    "    read_file = read_future + '_' + read_date + '.tdf'\n",
    "    return read_file\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def cal_weighted_IC(x: pd.Series, y: pd.Series, weight:pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    计算加权IC\n",
    "    :param x: 序列x\n",
    "    :param y: 序列y\n",
    "    :return: weighted_ic\n",
    "    \"\"\"\n",
    "    weight = weight / weight.sum()\n",
    "    weight_cov = (weight * x * y).sum() - (weight * x).sum() * (weight * y).sum()\n",
    "    weight_sigma1 = ((weight * x ** 2).sum() - (weight * x).sum() ** 2) ** (1 / 2)\n",
    "    weight_sigma2 = ((weight * y ** 2).sum() - (weight * y).sum() ** 2) ** (1 / 2)\n",
    "    weighted_ic = weight_cov / (weight_sigma1 * weight_sigma2)\n",
    "    return weighted_ic\n",
    "\n",
    "\n",
    "def run(start_date, end_date):\n",
    "\n",
    "    # 记录结果\n",
    "    multi_index = pd.MultiIndex.from_tuples(\n",
    "        [('因子', '因子名'), ('因子', '方向'), ('因子', '预测周期'), ('因子', '因子自相关性'),\n",
    "        ('RankIC', 'IC均值'), ('RankIC', 'IC_IR'), ('RankIC', 't值'), ('RankIC', '方向延续概率'),\n",
    "        ('WIC', 'IC均值'), ('WIC', 'IC_IR'), ('WIC', 't值'), ('WIC', '方向延续概率'),\n",
    "        ])  # 统计的项目\n",
    "    \n",
    "    result = pd.DataFrame(index=multi_index, columns=[]).T\n",
    "    writer = pd.ExcelWriter(os.path.join(pc.result_save_path, '单因子回测结果.xlsx'), engine='openpyxl')\n",
    "\n",
    "    # 逐因子计算单因子表现\n",
    "    for f_ in pc.factor_list:\n",
    "        \n",
    "        # 读取因子数据\n",
    "        factor_data = pd.read_pickle(os.path.join(fc.factor_save_path, '%s.pkl' % f_))\n",
    "\n",
    "        # 分离时间和日期\n",
    "        factor_data['date_date'] = pd.to_datetime(factor_data['minute'].dt.date)\n",
    "        factor_data['date_time'] = factor_data['minute'].dt.time\n",
    "\n",
    "        # 读取测试时间段\n",
    "        file_dates = factor_data['date_date'].drop_duplicates()\n",
    "        file_dates = file_dates[(file_dates > start_date) & (file_dates <= end_date)]\n",
    "        file_dates = file_dates.reset_index(drop=True)\n",
    "\n",
    "        # 记录因子逐日数据\n",
    "        day_result = pd.DataFrame(columns=['minute', 'T', 'IC', 'WIC', 'selfCorr', \\\n",
    "                                           '1', '2', '3', '4', '5', \\\n",
    "                                           '6', '7', '8', '9', '10'])\n",
    "\n",
    "        # 逐日计算单因子表现\n",
    "        for d_ in tqdm(file_dates, desc=f_):\n",
    "            \n",
    "            # 选取当日数据\n",
    "            f_path = read_file(d_)\n",
    "            f_return = pd.read_pickle(os.path.join(fc.kline_data, f_path))[['date', 'price', 'vol']]\n",
    "            f_return['date'] = f_return.apply(lambda x: pt.DoubleToDatetime(x['date']), axis=1)\n",
    "            f_return['minute'] = f_return['date'].dt.floor('T')\n",
    "            f_data = factor_data[factor_data['date_date'] == d_]\n",
    "\n",
    "            # 合并每分钟数据\n",
    "            f_return['amount'] = f_return['price'] * f_return['vol']\n",
    "            twap = f_return.groupby('minute').apply(lambda x: x['amount'].sum() / x['vol'].sum())\n",
    "            twap = twap.dropna()\n",
    "            twap = pd.DataFrame(twap, columns=['twap'])\n",
    "\n",
    "            # 合并因子数据\n",
    "            f_data = pd.merge(f_data, twap, on=['minute'])\n",
    "\n",
    "            # 计算因子自相关性\n",
    "            f_data['f_s1'] = f_data[f_].shift(1)\n",
    "            self_corr = f_data[f_].corr(f_data['f_s1'], method='spearman')\n",
    "\n",
    "            # 计算各个周期IC, WIC\n",
    "            for t_ in pc.t:\n",
    "\n",
    "                # 计算周期涨跌幅\n",
    "                f_data[f'yield_{t_}s'] = f_data['twap'].pct_change(periods=t_)\n",
    "                f_data[f'weight_{t_}s'] = sigmoid(f_data[f'yield_{t_}s'].abs() * 100) ** 0.5\n",
    "                tmp = f_data[[f_, f'yield_{t_}s', f'weight_{t_}s']]\n",
    "                tmp = tmp.dropna()\n",
    "\n",
    "                # 计算指标\n",
    "                ic = tmp[f'yield_{t_}s'].corr(tmp[f_], method='spearman')\n",
    "                wic = cal_weighted_IC(f_data[f_], f_data[f'yield_{t_}s'], f_data[f'weight_{t_}s'])\n",
    "\n",
    "                # 计算十分组图\n",
    "                group_data = f_data.sort_values(f_, ascending=False)\n",
    "                g1 = group_data[f'yield_{t_}s'].iloc[: int(len(f_data) * 0.1)]\n",
    "                g2 = group_data[f'yield_{t_}s'].iloc[int(len(f_data) * 0.1): int(len(f_data) * 0.2)]\n",
    "                g3 = group_data[f'yield_{t_}s'].iloc[int(len(f_data) * 0.2): int(len(f_data) * 0.3)]\n",
    "                g4 = group_data[f'yield_{t_}s'].iloc[int(len(f_data) * 0.3): int(len(f_data) * 0.4)]\n",
    "                g5 = group_data[f'yield_{t_}s'].iloc[int(len(f_data) * 0.4): int(len(f_data) * 0.5)]\n",
    "                g6 = group_data[f'yield_{t_}s'].iloc[int(len(f_data) * 0.5): int(len(f_data) * 0.6)]\n",
    "                g7 = group_data[f'yield_{t_}s'].iloc[int(len(f_data) * 0.6): int(len(f_data) * 0.7)]\n",
    "                g8 = group_data[f'yield_{t_}s'].iloc[int(len(f_data) * 0.7): int(len(f_data) * 0.8)]\n",
    "                g9 = group_data[f'yield_{t_}s'].iloc[int(len(f_data) * 0.8): int(len(f_data) * 0.9)]\n",
    "                g10 = group_data[f'yield_{t_}s'].iloc[int(len(f_data) * 0.9): ]\n",
    "\n",
    "                # 保存结果\n",
    "                day_result.loc[len(day_result)] = [d_, t_, ic, wic, self_corr, \\\n",
    "                                                   g1.mean(), g2.mean(), g3.mean(), g4.mean(), g5.mean(), \\\n",
    "                                                   g6.mean(), g7.mean(), g8.mean(), g9.mean(), g10.mean()]\n",
    "        \n",
    "\n",
    "        # 计算单因子表现\n",
    "        for t_ in pc.t:\n",
    "            day_result_t = day_result[day_result['T'] == t_]\n",
    "\n",
    "            # 因子指标\n",
    "            f_name = f_\n",
    "            f_direction = pc.factor_dict[f_]\n",
    "            f_t = t_\n",
    "            f_corr = day_result_t['selfCorr'].mean()\n",
    "\n",
    "            # IC指标\n",
    "            f_ic_mean = day_result_t['IC'].mean()\n",
    "            f_icir = day_result_t['IC'].mean() / day_result_t['IC'].std()\n",
    "            f_ic_tvalue = stats.ttest_1samp(day_result_t['IC'], 0, nan_policy='omit')[0]\n",
    "            f_ic_direction_rate = (day_result_t['IC'] * day_result_t['IC'].shift(-1) > 0).mean()\n",
    "\n",
    "            # WIC指标\n",
    "            f_wic_mean = day_result_t['WIC'].mean()\n",
    "            f_wicir = day_result_t['WIC'].mean() / day_result_t['WIC'].std()\n",
    "            f_wic_tvalue = stats.ttest_1samp(day_result_t['WIC'], 0, nan_policy='omit')[0]\n",
    "            f_wic_direction_rate = (day_result_t['WIC'] * day_result_t['WIC'].shift(-1) > 0).mean()\n",
    "\n",
    "            # 记录结果\n",
    "            result.loc[len(result)] = [\n",
    "                f_name, f_direction, f_t, f_corr,\n",
    "                f_ic_mean, f_icir, f_ic_tvalue, f_ic_direction_rate,\n",
    "                f_wic_mean, f_wicir, f_wic_tvalue, f_wic_direction_rate\n",
    "            ]\n",
    "\n",
    "            # 绘制十分组图\n",
    "            yield_groups = day_result_t[['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]\n",
    "            yield_groups = yield_groups.mean()\n",
    "            yield_groups.plot(kind='bar')\n",
    "            plt.savefig(os.path.join(pc.fig_save_path, f'{f_}_{t_}min.png'))\n",
    "            plt.clf()\n",
    "\n",
    "\n",
    "    result.to_excel(writer)\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    run(pc.start_date, pc.end_date)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "alpha001_start15_corr10: 100%|██████████| 645/645 [01:59<00:00,  5.41it/s]\n",
      "alpha002_start15: 100%|██████████| 645/645 [01:40<00:00,  6.41it/s]\n",
      "alpha003_start15_roll10: 100%|██████████| 645/645 [01:39<00:00,  6.47it/s]\n",
      "alpha004_start15_roll2_roll8: 100%|██████████| 645/645 [01:34<00:00,  6.82it/s]\n",
      "alpha005_start15_roll5: 100%|██████████| 645/645 [01:16<00:00,  8.42it/s]\n",
      "alpha006_start15_diff5: 100%|██████████| 645/645 [01:16<00:00,  8.44it/s]\n",
      "alpha007_start15_diff5: 100%|██████████| 645/645 [01:16<00:00,  8.45it/s]\n",
      "alpha008_start15_diff5: 100%|██████████| 645/645 [01:15<00:00,  8.51it/s]\n",
      "alpha009_start15_alpha0.29: 100%|██████████| 645/645 [01:16<00:00,  8.44it/s]\n",
      "alpha010_start15_roll10: 100%|██████████| 645/645 [01:18<00:00,  8.25it/s]\n",
      "alpha011_start15_roll10: 100%|██████████| 645/645 [01:19<00:00,  8.11it/s]\n",
      "alpha012_start15_roll10: 100%|██████████| 645/645 [01:15<00:00,  8.55it/s]\n",
      "alpha013_start15: 100%|██████████| 645/645 [01:16<00:00,  8.40it/s]\n",
      "alpha014_start15_shift10: 100%|██████████| 645/645 [01:20<00:00,  8.03it/s]\n",
      "alpha015_start15: 100%|██████████| 645/645 [01:26<00:00,  7.47it/s]\n",
      "alpha016_start15_roll6: 100%|██████████| 645/645 [01:25<00:00,  7.52it/s]\n",
      "alpha017_start15_roll10_diff5: 100%|██████████| 645/645 [01:28<00:00,  7.28it/s]\n",
      "alpha018_start15_shift5: 100%|██████████| 645/645 [01:30<00:00,  7.17it/s]\n",
      "alpha019_start15_shift5: 100%|██████████| 645/645 [01:29<00:00,  7.19it/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}