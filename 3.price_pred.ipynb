{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pyTSL as pt\n",
    "import warnings\n",
    "import datetime as dt\n",
    "warnings.filterwarnings('ignore')\n",
    "from Config import factor_config as fc\n",
    "from Config import model_config as mc\n",
    "\n",
    "head_future = pd.read_excel(os.path.join(fc.head_path, 'IC_head_future.xlsx')) # 每日主流合约\n",
    "\n",
    "def read_file(date):\n",
    "    '''\n",
    "    根据日期读取对应主头合约文件\n",
    "    '''\n",
    "    read_date = date.strftime('%Y%m%d')\n",
    "    next_idx = head_future[head_future['trade_date'] == date].index\n",
    "    if next_idx == 0:\n",
    "        return None\n",
    "    read_future = head_future.iloc[next_idx - 1]['IC'].values[0]\n",
    "    read_file = read_future + '_' + read_date + '.tdf'\n",
    "    return read_file\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    '''\n",
    "    读取因子及涨跌幅数据\n",
    "    '''\n",
    "\n",
    "    # # 读取因子时间段\n",
    "    # tmp = pd.read_pickle(os.path.join(fc.factor_save_path, '%s.pkl' % mc.model_factor[0]))\n",
    "    # file_dates = pd.to_datetime(tmp['minute'].dt.date).drop_duplicates()\n",
    "    # file_dates = file_dates[(file_dates > mc.start_date) & (file_dates <= mc.end_date)]\n",
    "    # file_dates = file_dates.reset_index(drop=True)\n",
    "\n",
    "    # # 选取因子数据\n",
    "    # factor_df = pd.DataFrame()\n",
    "    # for f_ in mc.model_factor:\n",
    "\n",
    "    #     f_data = pd.read_pickle(os.path.join(fc.factor_save_path, '%s.pkl' % f_))\n",
    "    #     f_data = f_data.reset_index(drop=True)\n",
    "    #     f_data = f_data.set_index('minute')\n",
    "    #     factor_df[f_] = f_data\n",
    "\n",
    "    # factor_df.to_excel('factor_data.xlsx')\n",
    "    factor_df = pd.read_excel('factor_data.xlsx')\n",
    "    file_dates = pd.to_datetime(factor_df['minute'].dt.date).drop_duplicates()\n",
    "    file_dates = file_dates[(file_dates > mc.start_date) & (file_dates <= mc.end_date)]\n",
    "    file_dates = file_dates.reset_index(drop=True)\n",
    "    factor_df['minute'] = pd.to_datetime(factor_df['minute'])\n",
    "    factor_df = factor_df[pd.to_datetime(factor_df['minute'].dt.date).isin(file_dates)]\n",
    "    factor_df = factor_df.set_index('minute')\n",
    "\n",
    "    # 获取涨跌幅数据\n",
    "    return_list = list()\n",
    "    for d_ in tqdm(file_dates, desc='Getting data'):\n",
    "        \n",
    "        # 选取期货数据\n",
    "        f_path = read_file(d_)\n",
    "        f_return = pd.read_pickle(os.path.join(fc.kline_data, f_path))[['date', 'price', 'vol']]\n",
    "        \n",
    "        # 处理时间\n",
    "        f_return['date'] = f_return.apply(lambda x: pt.DoubleToDatetime(x['date']), axis=1)\n",
    "        f_return['amount'] = f_return['price'] * f_return['vol']\n",
    "        f_return['minute'] = f_return['date'].dt.floor('T')\n",
    "        \n",
    "        # 合并每分钟数据\n",
    "        f_return['amount'] = f_return['price'] * f_return['vol']\n",
    "        vwap = f_return.groupby('minute').apply(lambda x: x['amount'].sum() / x['vol'].sum())\n",
    "        vwap = vwap.dropna()\n",
    "        vwap = pd.DataFrame(vwap, columns=['vwap'])\n",
    "\n",
    "        # 调整涨跌幅为yield_periods\n",
    "        vwap['return'] = vwap['vwap'].pct_change(mc.yield_periods)\n",
    "        vwap = vwap.reset_index()\n",
    "\n",
    "        vwap = vwap[['minute', 'return']]\n",
    "        return_list.append(vwap)\n",
    "\n",
    "    return_df = pd.concat(return_list)\n",
    "\n",
    "    # 合并涨跌幅与因子数据\n",
    "    return_df = return_df.set_index('minute')\n",
    "    return_df[mc.model_factor] = factor_df\n",
    "    return_df = return_df.dropna(subset=['return'])\n",
    "    return_df = return_df.reset_index('minute')\n",
    "\n",
    "    return return_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def train_xgb():\n",
    "\n",
    "    # 获取数据\n",
    "    data = get_data()\n",
    "\n",
    "    # 选取时间段\n",
    "    start_minute = dt.timedelta(minutes=mc.start_minute)\n",
    "    start_time = dt.datetime.combine(dt.datetime.today().date(), dt.time(9, 30))\n",
    "    start_time = start_time + start_minute\n",
    "    start_time = start_time.time()\n",
    "    data = data[data['minute'].dt.time >= start_time]\n",
    "\n",
    "    # 建立模型\n",
    "    xgb_model = xgb.XGBRegressor(**mc.xgb_params)\n",
    "\n",
    "    # 获取训练 & 测试起始日期\n",
    "    date = pd.date_range(mc.start_date, mc.end_date, freq='M', inclusive='both')\n",
    "    train_date = date[: -(mc.test_month + mc.train_month)]\n",
    "    test_date = date[(mc.train_month): -1]\n",
    "\n",
    "    data['date'] = pd.to_datetime(data['minute'].dt.date)\n",
    "    data = data.set_index('date')\n",
    "    # data = data.dropna()\n",
    "\n",
    "    # 保存结果\n",
    "    pred_list = list() # 预测结果\n",
    "    per_index = pd.MultiIndex.from_tuples([\n",
    "        ('训练集', 'MSE'),\n",
    "        ('测试集', 'MSE')\n",
    "    ])\n",
    "    per_res = pd.DataFrame(index=per_index, columns=test_date) # 模型表现\n",
    "\n",
    "    # 遍历训练日期\n",
    "    for i in tqdm(range(len(train_date)), desc='Training xgb'):\n",
    "        \n",
    "        # 训练 & 测试区间及数据\n",
    "        train_d = pd.date_range(train_date[i], train_date[i] + pd.offsets.MonthEnd(mc.train_month), inclusive='left')\n",
    "        test_d = pd.date_range(test_date[i], test_date[i] + pd.offsets.MonthEnd(mc.test_month), inclusive='left')\n",
    "\n",
    "        train_x = data.loc[train_d[0]: train_d[-1], mc.model_factor]\n",
    "        train_y = data.loc[train_d[0]: train_d[-1], 'return']\n",
    "        \n",
    "        test_x = data.loc[test_d[0]: test_d[-1], mc.model_factor]\n",
    "        test_y = data.loc[test_d[0]: test_d[-1], 'return']\n",
    "\n",
    "        minute = data.loc[test_d[0]: test_d[-1], 'minute']\n",
    "\n",
    "        # 数据标准化\n",
    "        scaler = StandardScaler()\n",
    "        train_x = pd.DataFrame(scaler.fit_transform(train_x.T), index=train_x.columns, columns=train_x.index).T\n",
    "        test_x = pd.DataFrame(scaler.fit_transform(test_x.T), index=test_x.columns, columns=test_x.index).T\n",
    "\n",
    "        # 训练模型\n",
    "        xgb_model.fit(train_x, train_y)\n",
    "\n",
    "        # 预测\n",
    "        pred_y_test = xgb_model.predict(test_x)\n",
    "        pred_y_train = xgb_model.predict(train_x)\n",
    "\n",
    "        # 效果评估\n",
    "        mse_test = mean_squared_error(test_y, pred_y_test)\n",
    "        mse_train = mean_squared_error(train_y, pred_y_train)\n",
    "\n",
    "        # 保存结果\n",
    "        # 预测结果\n",
    "        pred_res = pd.DataFrame(pred_y_test, index=minute, columns=[f'pred_{mc.yield_periods}min'])\n",
    "        pred_list.append(pred_res)\n",
    "\n",
    "        # 模型表现\n",
    "        per_res.loc[('训练集', 'MSE'), test_d[0]] = mse_train\n",
    "        per_res.loc[('测试集', 'MSE'), test_d[0]] = mse_test\n",
    "\n",
    "    # 保存文件\n",
    "    per_res = per_res.T\n",
    "    per_res.to_excel(os.path.join(mc.result_save_path, f'XGB_performance_{mc.yield_periods}min.xlsx'))\n",
    "\n",
    "    pred_df = pd.concat(pred_list)\n",
    "    pred_df.to_pickle(os.path.join(mc.result_save_path, f'xgb_{mc.yield_periods}min.pkl'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # 训练xgb\n",
    "    train_xgb()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Getting data: 100%|██████████| 483/483 [01:13<00:00,  6.58it/s]\n",
      "Training xgb: 100%|██████████| 21/21 [00:15<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}